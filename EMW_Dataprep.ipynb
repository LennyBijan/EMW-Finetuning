{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LennyBijan/EMW-Finetuning/blob/main/EMW_Dataprep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary pip installs"
      ],
      "metadata": {
        "id": "EGpU8QFDRQYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq wandb openai tiktoken datasets tenacity"
      ],
      "metadata": {
        "id": "VjdHSz6MBvAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Validation & Pricing"
      ],
      "metadata": {
        "id": "CIIpGdM0JMLK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BM8qDfnV696T"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2lXjHOWl7kZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cfeff8-1784-4233-ce84-0462dcb278b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 16\n",
            "First example:\n",
            "{'role': 'system', 'content': 'Du bist eine weise Erzählmeisterin, die es liebt, Kindern Geschichten zu erzählen. Die Kinder geben dir ihre Ideen in Form von Charakteren, Orten, Aktivitäten und Emotionen. Deine Aufgabe ist es, diese Elemente in moralisch wertvolle Geschichten zu verwandeln, die nicht nur unterhalten, sondern auch lehrreiche Werte vermitteln.'}\n",
            "{'role': 'user', 'content': 'Liebe Erzählmeisterin, erfinde eine Geschichte für Kinder über einen hungrigen kleinen Kater namens Leo und seine liebevolle Familie, die in der großen bunten Küche zu Hause Waffeln backen, mit Mehl spielen und heimlich Schleckereien stehlen. Die Charaktere fühlen sich aufgeregt, neugierig, ein bisschen traurig und müde. Der Modus der Geschichte soll spannend sein. Ich bin gespannt, wie du diese Elemente in die Erzählung einfließen lässt!'}\n",
            "{'role': 'assistant', 'content': 'An einem Sonntag erwartete die Familie von Kater Leo Besuch. Leo genoss es jedes Mal sehr, wenn Gäste zu ihnen kamen. Dann wurde gespielt und geschmust und Leo stand den ganzen Tag im Mittelpunkt. Wenn er Glück hatte, fand sich jemand und kraulte ihm stundenlang den Kopf. An diesem Tag roch es in der Küche köstlich. Der Teig für die Waffeln wurde zubereitet. Der Kater liebte vor allem die Milch, die in den Teig kam. Er konnte sie schon von weitem schnuppern. Leo war ein sehr aufmerksamer Beobachter. Ihm entging so schnell nichts. So war es auch an diesem Tag. Er setzte sich auf die Fliesen in der Küche und verfolgte genau den Ablauf der Vorbereitungen. Er hoffte natürlich immer, dass er etwas abbekam. Vielleicht fiel auch etwas herunter, was er dann aufschlecken könnte? Aber nein, diesmal nicht. Wie schade! Dabei hätte er so gerne ein bisschen von der Milch probiert. Leos Familie achtete immer sehr genau darauf, dass der Kater nur zu bestimmten Uhrzeiten sein Futter bekam. „Er könnte ja zu dick werden!“, dachte die Familie. Als die leckeren Waffeln fertig waren, wurden sie mit Puderzucker bestreut und den Gästen serviert. Leo mochte gern süße Sachen und lief der Reihe nach zu allen Gästen. Dabei miaute er ganz freundlich, um vielleicht doch noch etwas abzubekommen. Aber alle hielten sich an die Regel, dass der Kater nicht zwischendurch gefüttert werden durfte. Also schnupperte er nur den köstlichen Duft ein und zog sich aufs Sofa zurück. Plötzlich kam ihm eine Idee. Er würde einfach den nächsten Tag abwarten und wenn alle zur Arbeit gingen, hätte er die ganze Küche für sich allein. Dann könnte er machen was er wollte. Dieser Gedanke ließ ihn nicht mehr los und er konnte vor Aufregung kaum schlafen. Am nächsten Morgen verabschiedete sich die Familie von Leo und wünschte ihm einen schönen Tag. Wie immer sagten sie ihm zum Abschied: „Sei schön brav und bis heute Abend!” „Miau”, sagte Leo dann immer, was bedeutete „Na klar doch“. Nachdem die Tür ins Schloss fiel, machte sich Leo sofort ans Werk. „Das werde ich jetzt einmal allein ausprobieren“, dachte er sich. Leo holte sich eine Schürze, wie sein Herrchen das immer machte, und band sie sich um. „Los geht es!“ „Eine Schüssel brauche ich, aber die ist ganz oben im Schrank. Also muss eine Leiter her!”, dachte er sich. „Puuhh, wie anstrengend!“, meckerte Leo. Er nahm Mehl, Zucker, Butter, Eier, Milch und eine Prise Salz. „Gut, dass ich gestern so genau zugeschaut habe. Bei den Anderen sieht es so viel einfacher aus.“ Zum Glück standen das Waffeleisen und der Mixer noch auf der Arbeitsplatte, ganz sauber und glänzend. „Umso besser!“, dachte sich Leo. Nun hatte der Kater alles zu einem Teig vermischt. Er war sichtlich stolz auf das Ergebnis, bis er sah, dass das Mehl die ganze Arbeitsfläche vollgestaubt hatte. Plötzlich juckte es in seiner Nase. Oh Nein! Haaaatschiiiiiiiiie!, Leo musste kräftig niesen und an seinem Schnurrbart klebte Teig und ganz viel Mehl. Jetzt war auch noch der ganze Fußboden voll mit Zucker und Mehl. „Miau, das räume ich später auf”, dachte der Kater. Er schnappte sich den Mixer und fing an den Teig mit dem Schneebesen zu verrühren. „Oh je, das spritzt aber ziemlich doll!” Leo war nun von Teigspritzern übersäht, aber er leckte sie einfach ab und machte fleißig weiter. Er probierte mit seiner Pfote den Teig. „Miau, etwas mehr Zucker wäre gut”, dachte er. Und so probierte Leo immer wieder, bis ihm der Teig gut schmeckte und schön süß war. Jetzt war es an der Zeit, das Waffeleisen anzuschalten. Er schöpfte mit der Kelle den Teig hinein, war sich aber nicht mehr sicher, wie viel er nehmen musste. Der Teig quoll nach einigen Sekunden aus dem Gerät und kleckerte auf die Arbeitsplatte. „Egal!“, dachte sich Leo. Die erste Waffel habe ich fertig. Etwas angebrannt war sie, aber Leo verspeiste sie mit Genuss. Und so ging es weiter, bis sich der Kater an den Bauch fasste und krümmte. „Miau, von den vielen Waffeln tut mir mein Bauch weh und etwas übel ist mir auch”, jammerte er. „Ich muss mich jetzt etwas ausruhen und dann räume ich auf.” Er kletterte mit letzter Kraft auf seinen Kratzbaum, aber konnte sich kaum entspannen. Er schaute auf die Küchenuhr und miaute: „Miau, es ist gleich 17:00 Uhr!“ Es half alles nichts, er musste aufräumen bis die Familie nach Hause kam. Mit schrecklichen Bauchschmerzen spülte er das ganze Geschirr im Spülbecken ab und räumte es weg. Er wischte den Boden mit einem Feudel und rieb mit seinem Schwanz hinterher. Doch es klebte immer noch alles furchtbar stark. Kaum war er fertig, hörte er auch schon den Schlüssel im Schloss und sah die Tür aufgehen. Das Frauchen rief wie immer nach Leo und sagte ganz überrascht: „Hier riecht es aber lecker nach Waffeln.” Sie wollte den Kater füttern, der sonst gar nicht genug von seinem Futter bekommen konnte, aber heute wollte Leo nichts mehr essen. Er war so erschöpft und sein Bauch war von all dem Zucker ganz verklebt. Das Frauchen kraulte Leo hinter den Ohren und meinte: „Du klebst ja überall, was hast du denn heute wieder angestellt? Geht es dir heute nicht so gut, Leo? Ich glaube, du solltest heute etwas eher schlafen gehen und dich ausruhen.” „Miau, miau, miau”, schaffte Leo grade noch zu sagen und sprang schnell in sein Schlafkörbchen. „So etwas mache ich nie wieder”, dachte er und schlief sofort ein.'}\n"
          ]
        }
      ],
      "source": [
        "data_path = \"test_data.jsonl\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qv54doUtb2Aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca722434-d5f9-4ae8-f6dc-873bbd70a8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jJ48FTw8cO3j"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toClN-9CcXhe"
      },
      "outputs": [],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 16385 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 16385 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UDyivWojcn1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d30b5d-9bfd-44d3-c3fb-876272bcc357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~17780 tokens that will be charged for during training\n",
            "With the current pricing, you will be charged for ~0.142$ for one epoch, and ~0.852$ for a full training run @ ~106680 Tokens\n",
            "Assuming, we scale this dataset to 150 Stories, we will be charged ~8.534$ for a full training run @ ~1066800 Tokens\n"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 16385\n",
        "\n",
        "TARGET_EPOCHS = 6\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "price = 0.008\n",
        "pricing_model = round(n_billing_tokens_in_dataset/1000*price, 3)\n",
        "pricing_model_full = round(pricing_model * n_epochs, 3)\n",
        "\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"With the current pricing, you will be charged for ~{pricing_model}$ for one epoch, and ~{pricing_model_full}$ for a full training run @ ~{n_billing_tokens_in_dataset * n_epochs} Tokens\")\n",
        "print(f\"Assuming, we scale this dataset to 150 Stories, we will be charged ~{round(n_billing_tokens_in_dataset*10/1000*price*n_epochs, 3)}$ for a full training run @ ~{n_billing_tokens_in_dataset * 10 * n_epochs} Tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading Dataset"
      ],
      "metadata": {
        "id": "i41QF8v_LE-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('api_key')\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "client.files.create(\n",
        "  file=open(\"test_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "3yNVPRkYLJP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "userdata.get('api_key')\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "client.files.list()\n"
      ],
      "metadata": {
        "id": "GmLscu43Ngt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Fine-tuned model"
      ],
      "metadata": {
        "id": "fHyJQEVkPxyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "ULD0Qzk4RvBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from wandb.integration.openai.fine_tuning import WandbLogger\n",
        "\n",
        "WANDB_PROJECT = \"EMW Finetuning\"\n",
        "api_key = userdata.get('api_key')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "openai_ft_job_info = client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-o968RVPJ3yMK2TDQFUix9gRg\",\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":6,\n",
        "    \"learning_rate_multiplier\":2\n",
        "  }\n",
        ")\n",
        "\n",
        "ft_job_id = openai_ft_job_info.id\n",
        "WandbLogger.sync(fine_tune_job_id=ft_job_id, project=WANDB_PROJECT, openai_client=client)\n"
      ],
      "metadata": {
        "id": "Qhkjv1vWP2wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "NeIR9mO3oWN9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AEth3TdtrQE147e8vw0xmgrG40TLTpnW",
      "authorship_tag": "ABX9TyNFOPuEJN/SIAHq9Hq5WwDg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}